{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nova Experiment Analysis Template\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides automated analysis and visualization of nova simulation experiments. It analyzes the output from `scripts/analyze_vcf_results.py` to generate comprehensive performance metrics and publication-ready visualizations.\n",
    "\n",
    "## Template Usage\n",
    "\n",
    "1. **Configure Parameters**: Modify the experiment configuration in the cell below\n",
    "2. **Run All Cells**: Execute the entire notebook for automated analysis\n",
    "3. **Review Results**: Examine the generated plots and summary statistics\n",
    "\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIGURATION - Modify these parameters for each experiment\n",
    "EXPERIMENT_NAME = \"Nova Simulation Analysis\"\n",
    "DATA_DIRECTORY = \"../output\"  # Path to experiment output directory\n",
    "OUTPUT_PREFIX = \"nova\"  # Prefix used in analyze_vcf_results.py output files\n",
    "ANALYSIS_TITLE = \"Nova Variant Detection Performance Analysis\"\n",
    "\n",
    "# Optional: Override expected insertion counts if needed\n",
    "# Leave as None to auto-detect from data\n",
    "EXPECTED_INSERTIONS = None  # e.g., {'random': 400, 'simple': 200, 'AluYa5': 100}\n",
    "\n",
    "# Display options\n",
    "FIGURE_SIZE = (12, 8)\n",
    "DPI = 100\n",
    "SAVE_FIGURES = False  # Set to True to save plots as PNG files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = FIGURE_SIZE\n",
    "plt.rcParams['figure.dpi'] = DPI\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "\n",
    "# Define consistent color scheme\n",
    "COLORS = {\n",
    "    'primary': '#2E8B57',     # Sea Green\n",
    "    'secondary': '#4682B4',   # Steel Blue\n",
    "    'accent': '#CD5C5C',      # Indian Red\n",
    "    'success': '#2ECC71',     # Emerald\n",
    "    'warning': '#F39C12',     # Orange\n",
    "    'danger': '#E74C3C'       # Red\n",
    "}\n",
    "\n",
    "print(f\"Analysis setup complete for: {EXPERIMENT_NAME}\")\n",
    "print(f\"Timestamp: {pd.Timestamp.now()}\")\n",
    "print(f\"Data directory: {DATA_DIRECTORY}\")\n",
    "print(f\"Output prefix: {OUTPUT_PREFIX}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data files\n",
    "data_path = Path(DATA_DIRECTORY)\n",
    "csv_file = data_path / f\"{OUTPUT_PREFIX}_analysis.csv\"\n",
    "json_file = data_path / f\"{OUTPUT_PREFIX}_analysis.json\"\n",
    "\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "print(f\"CSV file: {csv_file}\")\n",
    "print(f\"JSON file: {json_file}\")\n",
    "\n",
    "# Load CSV data\n",
    "if csv_file.exists():\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"CSV loaded: {len(df)} records\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Required CSV file not found: {csv_file}\")\n",
    "\n",
    "# Load JSON summary (optional)\n",
    "summary_data = None\n",
    "if json_file.exists():\n",
    "    with open(json_file, 'r') as f:\n",
    "        summary_data = json.load(f)\n",
    "    print(f\"JSON summary loaded\")\n",
    "else:\n",
    "    print(f\"JSON summary not found, will calculate from CSV data\")\n",
    "\n",
    "# Validate required columns\n",
    "required_cols = ['variant_index', 'composition', 'is_single_nova_only']\n",
    "missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "print(f\"Data validation passed\")\n",
    "\n",
    "# Quick summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"EXPERIMENT: {EXPERIMENT_NAME}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Basic counts for context\n",
    "total_variants = len(df)\n",
    "unique_variants = df['variant_index'].nunique()\n",
    "print(f\"\\nTotal variant records: {total_variants:,}\")\n",
    "print(f\"Unique variants: {unique_variants:,}\")\n",
    "\n",
    "# Check for optional columns\n",
    "optional_cols = ['has_genomic_clustering', 'exact_size_match', 'close_size_match']\n",
    "available_optional = [col for col in optional_cols if col in df.columns]\n",
    "print(f\"\\nOptional columns available: {available_optional}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis\n",
    "\n",
    "### True Positive Analysis\n",
    "\n",
    "Analyzing the detection performance for simulated insertions. True positives are defined as single nova-only variant calls - the ideal outcome for de novo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positive Analysis by Insertion Type\n",
    "\n",
    "# Get unique variants (avoid double-counting if multiple nova reads per variant)\n",
    "unique_df = df.groupby('variant_index').agg({\n",
    "    'is_single_nova_only': 'first',\n",
    "    'insertion_type': 'first',\n",
    "    'composition': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Create true positive analysis visualization\n",
    "if 'insertion_type' in df.columns and df['insertion_type'].notna().any():\n",
    "    # Calculate metrics by insertion type\n",
    "    tp_by_type = []\n",
    "    insertion_types = unique_df['insertion_type'].dropna().unique()\n",
    "    \n",
    "    for ins_type in sorted(insertion_types):\n",
    "        type_df = unique_df[unique_df['insertion_type'] == ins_type]\n",
    "        total_detected = len(type_df)\n",
    "        true_positives = len(type_df[type_df['is_single_nova_only'] == True])\n",
    "        \n",
    "        # Calculate rates\n",
    "        tp_rate = (true_positives / total_detected * 100) if total_detected > 0 else 0\n",
    "        \n",
    "        tp_by_type.append({\n",
    "            'insertion_type': ins_type,\n",
    "            'total_detected': total_detected,\n",
    "            'true_positives': true_positives,\n",
    "            'tp_rate': tp_rate\n",
    "        })\n",
    "    \n",
    "    tp_df = pd.DataFrame(tp_by_type)\n",
    "    \n",
    "    # Create 2x2 subplot figure\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: True positive rates by insertion type\n",
    "    if len(tp_df) > 0:\n",
    "        bars1 = ax1.bar(tp_df['insertion_type'], tp_df['tp_rate'], \n",
    "                        color=COLORS['primary'], alpha=0.8)\n",
    "        ax1.set_title('True Positive Rates by Insertion Type', fontsize=14, fontweight='bold')\n",
    "        ax1.set_ylabel('True Positive Rate (%)')\n",
    "        ax1.set_xlabel('Insertion Type')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        ax1.set_ylim(0, 105)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in bars1:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                     f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Overall composition breakdown\n",
    "    composition_data = unique_df['composition'].value_counts()\n",
    "    colors = [COLORS['success'], COLORS['warning'], COLORS['danger']]\n",
    "    wedges, texts, autotexts = ax2.pie(composition_data.values, labels=composition_data.index, \n",
    "                                      autopct='%1.1f%%', colors=colors[:len(composition_data)])\n",
    "    ax2.set_title('Overall Read Composition', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Make percentage text bold\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "    \n",
    "    # Plot 3: Detection counts by type\n",
    "    if len(tp_df) > 0:\n",
    "        x = np.arange(len(tp_df))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars3a = ax3.bar(x - width/2, tp_df['true_positives'], width, \n",
    "                         label='True Positives', color=COLORS['success'], alpha=0.8)\n",
    "        bars3b = ax3.bar(x + width/2, tp_df['total_detected'] - tp_df['true_positives'], width,\n",
    "                         label='False Positives', color=COLORS['danger'], alpha=0.8)\n",
    "        \n",
    "        ax3.set_title('Detection Counts by Insertion Type', fontsize=14, fontweight='bold')\n",
    "        ax3.set_ylabel('Number of Variants')\n",
    "        ax3.set_xlabel('Insertion Type')\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(tp_df['insertion_type'], rotation=45)\n",
    "        ax3.legend()\n",
    "        ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Performance metrics summary\n",
    "    overall_tp_rate = (unique_df['is_single_nova_only'].sum() / len(unique_df) * 100) if len(unique_df) > 0 else 0\n",
    "    overall_fp_rate = 100 - overall_tp_rate\n",
    "    detection_quality = overall_tp_rate  # Same as TP rate when looking at unique variants\n",
    "    \n",
    "    metrics = ['True Positive Rate', 'False Positive Rate', 'Detection Quality']\n",
    "    values = [overall_tp_rate, overall_fp_rate, detection_quality]\n",
    "    colors_metrics = [COLORS['success'], COLORS['danger'], COLORS['primary']]\n",
    "    \n",
    "    bars4 = ax4.bar(metrics, values, color=colors_metrics, alpha=0.8)\n",
    "    ax4.set_title('Overall Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    ax4.set_ylabel('Percentage (%)')\n",
    "    ax4.set_ylim(0, 105)\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars4:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                 f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(data_path / f\"{OUTPUT_PREFIX}_true_positive_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print brief summary\n",
    "    print(f\"\\nTRUE POSITIVE ANALYSIS SUMMARY\")\n",
    "    print(f\"Overall true positive rate: {overall_tp_rate:.1f}%\")\n",
    "    if len(tp_df) > 0:\n",
    "        print(f\"Best performing type: {tp_df.loc[tp_df['tp_rate'].idxmax(), 'insertion_type']} ({tp_df['tp_rate'].max():.1f}%)\")\n",
    "        print(f\"Worst performing type: {tp_df.loc[tp_df['tp_rate'].idxmin(), 'insertion_type']} ({tp_df['tp_rate'].min():.1f}%)\")\n",
    "    \n",
    "else:\n",
    "    print(\"Warning: Insertion type data not available in CSV file\")\n",
    "    print(\"Cannot generate insertion type analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive Analysis\n",
    "\n",
    "Analyzing variants that are **not** single nova-only calls. These represent false positives in de novo simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# False Positive Analysis\n",
    "\n",
    "# Get false positive variants\n",
    "fp_variants = df[df['is_single_nova_only'] == False]\n",
    "unique_fp = fp_variants.groupby('variant_index').first().reset_index()\n",
    "\n",
    "print(f\"False Positive Analysis: {len(unique_fp)} unique false positive variants\")\n",
    "\n",
    "if len(unique_fp) > 0:\n",
    "    # Create false positive analysis visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Plot 1: False positive composition breakdown\n",
    "    fp_composition = unique_fp['composition'].value_counts()\n",
    "    colors = [COLORS['warning'], COLORS['danger']]\n",
    "    bars1 = ax1.bar(fp_composition.index, fp_composition.values, \n",
    "                    color=colors[:len(fp_composition)], alpha=0.8)\n",
    "    ax1.set_title('False Positive Composition', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Variants')\n",
    "    ax1.set_xlabel('Composition Type')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                 f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Genomic clustering analysis (if available)\n",
    "    if 'has_genomic_clustering' in unique_fp.columns:\n",
    "        clustering_counts = unique_fp['has_genomic_clustering'].value_counts()\n",
    "        labels = ['No Clustering', 'Genomic Clustering']\n",
    "        sizes = [clustering_counts.get(False, 0), clustering_counts.get(True, 0)]\n",
    "        colors_clustering = [COLORS['success'], COLORS['danger']]\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(sizes, labels=labels, autopct='%1.1f%%', \n",
    "                                          colors=colors_clustering)\n",
    "        ax2.set_title('Genomic Clustering in False Positives', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Make percentage text bold\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontweight('bold')\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'Genomic clustering\\ndata not available', \n",
    "                ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "        ax2.set_title('Genomic Clustering Analysis', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    # Plot 3: Support read distribution for false positives\n",
    "    if 'support_reads' in unique_fp.columns:\n",
    "        # Limit to reasonable range for visualization\n",
    "        support_reads = unique_fp['support_reads'].values\n",
    "        support_reads = support_reads[support_reads <= 20]  # Cap at 20 for better visualization\n",
    "        \n",
    "        ax3.hist(support_reads, bins=range(1, max(support_reads)+2), \n",
    "                color=COLORS['secondary'], alpha=0.7, edgecolor='black')\n",
    "        ax3.set_title('Support Read Distribution (False Positives)', fontsize=14, fontweight='bold')\n",
    "        ax3.set_xlabel('Number of Supporting Reads')\n",
    "        ax3.set_ylabel('Number of Variants')\n",
    "        ax3.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_support = np.mean(unique_fp['support_reads'])\n",
    "        ax3.axvline(mean_support, color=COLORS['danger'], linestyle='--', linewidth=2, \n",
    "                   label=f'Mean: {mean_support:.1f}')\n",
    "        ax3.legend()\n",
    "    \n",
    "    # Plot 4: Nova fraction distribution for false positives\n",
    "    if 'nova_fraction' in unique_fp.columns:\n",
    "        ax4.hist(unique_fp['nova_fraction'], bins=20, color=COLORS['accent'], alpha=0.7, edgecolor='black')\n",
    "        ax4.set_title('Nova Fraction Distribution (False Positives)', fontsize=14, fontweight='bold')\n",
    "        ax4.set_xlabel('Nova Fraction')\n",
    "        ax4.set_ylabel('Number of Variants')\n",
    "        ax4.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_nova_fraction = np.mean(unique_fp['nova_fraction'])\n",
    "        ax4.axvline(mean_nova_fraction, color=COLORS['danger'], linestyle='--', linewidth=2,\n",
    "                   label=f'Mean: {mean_nova_fraction:.2f}')\n",
    "        ax4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(data_path / f\"{OUTPUT_PREFIX}_false_positive_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print brief summary\n",
    "    print(f\"\\nFALSE POSITIVE SUMMARY\")\n",
    "    print(f\"Total false positives: {len(unique_fp):,}\")\n",
    "    print(f\"Composition breakdown:\")\n",
    "    for comp_type, count in fp_composition.items():\n",
    "        percentage = (count / len(unique_fp) * 100)\n",
    "        print(f\"  {comp_type}: {count:,} ({percentage:.1f}%)\")\n",
    "    \n",
    "    if 'has_genomic_clustering' in unique_fp.columns:\n",
    "        clustering_count = len(unique_fp[unique_fp['has_genomic_clustering'] == True])\n",
    "        clustering_pct = (clustering_count / len(unique_fp) * 100)\n",
    "        print(f\"Genomic clustering: {clustering_count:,} ({clustering_pct:.1f}%)\")\n",
    "        \n",
    "else:\n",
    "    print(\"No false positive variants detected!\")\n",
    "    \n",
    "    # Create a simple message plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    ax.text(0.5, 0.5, 'No False Positives Detected!\\n\\nExcellent simulation quality', \n",
    "            ha='center', va='center', transform=ax.transAxes, \n",
    "            fontsize=20, fontweight='bold', color=COLORS['success'])\n",
    "    ax.set_title('False Positive Analysis', fontsize=16, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(data_path / f\"{OUTPUT_PREFIX}_false_positive_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Analysis\n",
    "\n",
    "### Read Composition and Size Accuracy\n",
    "\n",
    "Detailed analysis of read support patterns and insertion size accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed Analysis with comprehensive visualizations\n",
    "\n",
    "# Get unique variants for this analysis\n",
    "unique_analysis_df = df.groupby('variant_index').agg({\n",
    "    'support_reads': 'first',\n",
    "    'nova_reads': 'first',\n",
    "    'nova_fraction': 'first',\n",
    "    'composition': 'first',\n",
    "    'is_single_nova_only': 'first',\n",
    "    'exact_size_match': 'first' if 'exact_size_match' in df.columns else lambda x: None,\n",
    "    'close_size_match': 'first' if 'close_size_match' in df.columns else lambda x: None,\n",
    "    'reasonable_size_match': 'first' if 'reasonable_size_match' in df.columns else lambda x: None,\n",
    "    'chrom': 'first',\n",
    "    'svtype': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Create comprehensive analysis visualization\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Support read distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "support_reads = unique_analysis_df['support_reads'].values\n",
    "support_reads_capped = support_reads[support_reads <= 20]  # Cap for better visualization\n",
    "ax1.hist(support_reads_capped, bins=range(1, 21), color=COLORS['primary'], alpha=0.7, edgecolor='black')\n",
    "ax1.set_title('Support Read Distribution', fontweight='bold')\n",
    "ax1.set_xlabel('Number of Supporting Reads')\n",
    "ax1.set_ylabel('Number of Variants')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add statistics\n",
    "mean_support = np.mean(support_reads)\n",
    "median_support = np.median(support_reads)\n",
    "ax1.axvline(mean_support, color=COLORS['danger'], linestyle='--', linewidth=2, label=f'Mean: {mean_support:.1f}')\n",
    "ax1.axvline(median_support, color=COLORS['warning'], linestyle=':', linewidth=2, label=f'Median: {median_support:.1f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Nova fraction distribution\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "nova_fractions = unique_analysis_df['nova_fraction'].values\n",
    "ax2.hist(nova_fractions, bins=20, color=COLORS['secondary'], alpha=0.7, edgecolor='black')\n",
    "ax2.set_title('Nova Fraction Distribution', fontweight='bold')\n",
    "ax2.set_xlabel('Nova Fraction')\n",
    "ax2.set_ylabel('Number of Variants')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add statistics\n",
    "mean_nova_frac = np.mean(nova_fractions)\n",
    "ax2.axvline(mean_nova_frac, color=COLORS['danger'], linestyle='--', linewidth=2, label=f'Mean: {mean_nova_frac:.2f}')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Composition breakdown\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "composition_counts = unique_analysis_df['composition'].value_counts()\n",
    "colors_comp = [COLORS['success'], COLORS['warning'], COLORS['danger']]\n",
    "wedges, texts, autotexts = ax3.pie(composition_counts.values, labels=composition_counts.index, \n",
    "                                  autopct='%1.1f%%', colors=colors_comp[:len(composition_counts)])\n",
    "ax3.set_title('Overall Composition', fontweight='bold')\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "\n",
    "# Plot 4: Size accuracy analysis (if available)\n",
    "if 'exact_size_match' in unique_analysis_df.columns and unique_analysis_df['exact_size_match'].notna().any():\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    exact_count = len(unique_analysis_df[unique_analysis_df['exact_size_match'] == True])\n",
    "    close_count = len(unique_analysis_df[unique_analysis_df['close_size_match'] == True])\n",
    "    reasonable_count = len(unique_analysis_df[unique_analysis_df['reasonable_size_match'] == True])\n",
    "    total_with_size = len(unique_analysis_df[unique_analysis_df['exact_size_match'].notna()])\n",
    "    \n",
    "    if total_with_size > 0:\n",
    "        categories = ['Exact\\n(0bp diff)', 'Close\\n(≤10bp diff)', 'Reasonable\\n(≥80% ratio)']\n",
    "        counts = [exact_count, close_count, reasonable_count]\n",
    "        percentages = [(count / total_with_size * 100) for count in counts]\n",
    "        \n",
    "        bars4 = ax4.bar(categories, percentages, color=[COLORS['success'], COLORS['warning'], COLORS['secondary']], alpha=0.8)\n",
    "        ax4.set_title('Size Accuracy Rates', fontweight='bold')\n",
    "        ax4.set_ylabel('Percentage of Variants (%)')\n",
    "        ax4.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, pct in zip(bars4, percentages):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 1,\n",
    "                     f'{pct:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "else:\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    ax4.text(0.5, 0.5, 'Size accuracy\\ndata not available', ha='center', va='center', \n",
    "             transform=ax4.transAxes, fontsize=12)\n",
    "    ax4.set_title('Size Accuracy Analysis', fontweight='bold')\n",
    "\n",
    "# Plot 5: Chromosomal distribution\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "chrom_counts = unique_analysis_df['chrom'].value_counts().head(10)  # Top 10 chromosomes\n",
    "bars5 = ax5.bar(range(len(chrom_counts)), chrom_counts.values, color=COLORS['accent'], alpha=0.8)\n",
    "ax5.set_title('Top 10 Chromosomes', fontweight='bold')\n",
    "ax5.set_ylabel('Number of Variants')\n",
    "ax5.set_xlabel('Chromosome')\n",
    "ax5.set_xticks(range(len(chrom_counts)))\n",
    "ax5.set_xticklabels(chrom_counts.index, rotation=45)\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 6: SV type distribution\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "svtype_counts = unique_analysis_df['svtype'].value_counts()\n",
    "bars6 = ax6.bar(svtype_counts.index, svtype_counts.values, color=COLORS['primary'], alpha=0.8)\n",
    "ax6.set_title('Structural Variant Types', fontweight='bold')\n",
    "ax6.set_ylabel('Number of Variants')\n",
    "ax6.set_xlabel('SV Type')\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 7: Support reads vs Nova fraction scatter\n",
    "ax7 = fig.add_subplot(gs[2, :])\n",
    "scatter = ax7.scatter(unique_analysis_df['support_reads'], unique_analysis_df['nova_fraction'], \n",
    "                     c=unique_analysis_df['is_single_nova_only'].map({True: COLORS['success'], False: COLORS['danger']}),\n",
    "                     alpha=0.6, s=50)\n",
    "ax7.set_title('Support Reads vs Nova Fraction', fontweight='bold')\n",
    "ax7.set_xlabel('Number of Supporting Reads')\n",
    "ax7.set_ylabel('Nova Fraction')\n",
    "ax7.grid(True, alpha=0.3)\n",
    "ax7.set_xlim(0, min(20, unique_analysis_df['support_reads'].max() + 1))\n",
    "ax7.set_ylim(-0.05, 1.05)\n",
    "\n",
    "# Add legend for scatter plot\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor=COLORS['success'], label='True Positives'),\n",
    "                  Patch(facecolor=COLORS['danger'], label='False Positives')]\n",
    "ax7.legend(handles=legend_elements)\n",
    "\n",
    "plt.suptitle(f'{EXPERIMENT_NAME}: Detailed Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "if SAVE_FIGURES:\n",
    "    plt.savefig(data_path / f\"{OUTPUT_PREFIX}_detailed_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\nDETAILED ANALYSIS SUMMARY\")\n",
    "print(f\"Total unique variants: {len(unique_analysis_df):,}\")\n",
    "print(f\"Mean support reads: {mean_support:.1f}\")\n",
    "print(f\"Mean nova fraction: {mean_nova_frac:.3f}\")\n",
    "print(f\"Single-read variants: {len(unique_analysis_df[unique_analysis_df['support_reads'] == 1]):,}\")\n",
    "print(f\"Perfect nova fraction (1.0): {len(unique_analysis_df[unique_analysis_df['nova_fraction'] == 1.0]):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}